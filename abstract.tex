BCI algorithm development has long been hampered by two major issues: Small
sample sets and a lack of reproducibility. We offer a solution to both of these
problems in the form of a software suite that simplifies and streamlines both
the issue of finding, downloading, and preprocessing data in a reliable manner,
and the issue of a reliable interface to use machine learning methods. By
building on recent advances in software for signal analysis implemented in the MNE toolkit,
and the unified framework for machine learning offered by the scikit-learn
project, we offer a system that can improve BCI algorithm development. To
validate this system, we analyze of a set of state-of-the-art decoding
algorithms across many open access datasets. Our analysis confirms that
different datasets can result in very different results for identical processing
pipelines, highlighting the need for a trustworthy algorithm benchmarking in the
field of BCIs., and further that many previously validated results do not hold
up when applied across different datasets, which has wide-reaching implications
for practical BCIs.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
